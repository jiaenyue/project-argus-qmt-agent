#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
WebSocket æ€§èƒ½ä¼˜åŒ–å’Œæœ€ä½³å®è·µæ•™ç¨‹

æœ¬æ•™ç¨‹æ·±å…¥æ¢è®¨ WebSocket å®æ—¶æ•°æ®ç³»ç»Ÿçš„æ€§èƒ½ä¼˜åŒ–æŠ€å·§å’Œæœ€ä½³å®è·µï¼Œ
åŒ…æ‹¬è¿æ¥ä¼˜åŒ–ã€æ•°æ®å‹ç¼©ã€æ‰¹é‡å¤„ç†ã€å†…å­˜ç®¡ç†ã€é”™è¯¯å¤„ç†ç­‰æ–¹é¢ã€‚

å­¦ä¹ ç›®æ ‡ï¼š
1. æŒæ¡ WebSocket è¿æ¥æ€§èƒ½ä¼˜åŒ–æŠ€å·§
2. å­¦ä¼šæ•°æ®å‹ç¼©å’Œæ‰¹é‡å¤„ç†ç­–ç•¥
3. äº†è§£å†…å­˜ç®¡ç†å’Œèµ„æºä¼˜åŒ–æ–¹æ³•
4. æŒæ¡é”™è¯¯å¤„ç†å’Œæ¢å¤æœ€ä½³å®è·µ
5. å­¦ä¼šæ€§èƒ½ç›‘æ§å’Œè°ƒä¼˜æ–¹æ³•

å‰ç½®æ¡ä»¶ï¼š
- å·²å®Œæˆ WebSocket åŸºç¡€æ•™ç¨‹ï¼ˆ08-09ï¼‰
- äº†è§£ Python å¼‚æ­¥ç¼–ç¨‹
- ç†Ÿæ‚‰æ€§èƒ½åˆ†æå·¥å…·

ä½œè€…: Argus å¼€å‘å›¢é˜Ÿ
åˆ›å»ºæ—¶é—´: 2025-01-15
æœ€åæ›´æ–°: 2025-01-15
"""

import asyncio
import json
import logging
import time
import sys
import gc
import psutil
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
import websockets
import zlib
import gzip
import pickle
from collections import deque, defaultdict
from dataclasses import dataclass, field
import numpy as np
import matplotlib.pyplot as plt
from concurrent.futures import ThreadPoolExecutor
import aiofiles
import uvloop  # é«˜æ€§èƒ½äº‹ä»¶å¾ªç¯ï¼ˆéœ€è¦å®‰è£…ï¼špip install uvloopï¼‰

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    timestamp: datetime = field(default_factory=datetime.now)
    cpu_percent: float = 0.0
    memory_mb: float = 0.0
    network_bytes_sent: int = 0
    network_bytes_recv: int = 0
    message_rate: float = 0.0
    latency_ms: float = 0.0
    connection_count: int = 0
    error_rate: float = 0.0


@dataclass
class OptimizationConfig:
    """ä¼˜åŒ–é…ç½®"""
    # è¿æ¥ä¼˜åŒ–
    max_connections: int = 1000
    connection_pool_size: int = 100
    ping_interval: int = 20
    ping_timeout: int = 10
    
    # æ•°æ®å¤„ç†ä¼˜åŒ–
    enable_compression: bool = True
    compression_threshold: int = 1024
    batch_size: int = 100
    batch_timeout: float = 0.1
    
    # å†…å­˜ç®¡ç†
    max_message_history: int = 10000
    gc_interval: float = 60.0
    memory_threshold_mb: float = 512.0
    
    # æ€§èƒ½ç›‘æ§
    metrics_interval: float = 5.0
    enable_profiling: bool = False


class CompressionManager:
    """æ•°æ®å‹ç¼©ç®¡ç†å™¨
    
    æä¾›å¤šç§å‹ç¼©ç®—æ³•å’Œè‡ªé€‚åº”å‹ç¼©ç­–ç•¥
    """
    
    def __init__(self, config: OptimizationConfig):
        self.config = config
        self.compression_stats = {
            'total_compressed': 0,
            'total_original_size': 0,
            'total_compressed_size': 0,
            'compression_time': 0.0
        }
    
    def compress_data(self, data: str, algorithm: str = 'gzip') -> bytes:
        """å‹ç¼©æ•°æ®
        
        Args:
            data: åŸå§‹æ•°æ®
            algorithm: å‹ç¼©ç®—æ³• ('gzip', 'zlib', 'lz4')
            
        Returns:
            bytes: å‹ç¼©åçš„æ•°æ®
        """
        if len(data) < self.config.compression_threshold:
            return data.encode('utf-8')
        
        start_time = time.time()
        original_size = len(data.encode('utf-8'))
        
        try:
            if algorithm == 'gzip':
                compressed = gzip.compress(data.encode('utf-8'))
            elif algorithm == 'zlib':
                compressed = zlib.compress(data.encode('utf-8'))
            else:
                # é»˜è®¤ä½¿ç”¨ gzip
                compressed = gzip.compress(data.encode('utf-8'))
            
            # æ›´æ–°ç»Ÿè®¡
            compression_time = time.time() - start_time
            self.compression_stats['total_compressed'] += 1
            self.compression_stats['total_original_size'] += original_size
            self.compression_stats['total_compressed_size'] += len(compressed)
            self.compression_stats['compression_time'] += compression_time
            
            return compressed
            
        except Exception as e:
            logger.error(f"æ•°æ®å‹ç¼©å¤±è´¥: {e}")
            return data.encode('utf-8')
    
    def decompress_data(self, data: bytes, algorithm: str = 'gzip') -> str:
        """è§£å‹æ•°æ®
        
        Args:
            data: å‹ç¼©æ•°æ®
            algorithm: å‹ç¼©ç®—æ³•
            
        Returns:
            str: è§£å‹åçš„æ•°æ®
        """
        try:
            if algorithm == 'gzip':
                decompressed = gzip.decompress(data)
            elif algorithm == 'zlib':
                decompressed = zlib.decompress(data)
            else:
                decompressed = gzip.decompress(data)
            
            return decompressed.decode('utf-8')
            
        except Exception as e:
            logger.error(f"æ•°æ®è§£å‹å¤±è´¥: {e}")
            return data.decode('utf-8')
    
    def get_compression_ratio(self) -> float:
        """è·å–å‹ç¼©æ¯”"""
        if self.compression_stats['total_original_size'] == 0:
            return 0.0
        
        return (1 - self.compression_stats['total_compressed_size'] / 
                self.compression_stats['total_original_size']) * 100
    
    def get_compression_stats(self) -> Dict[str, Any]:
        """è·å–å‹ç¼©ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.compression_stats.copy()
        stats['compression_ratio'] = self.get_compression_ratio()
        stats['avg_compression_time'] = (
            stats['compression_time'] / max(stats['total_compressed'], 1)
        )
        return stats


class BatchProcessor:
    """æ‰¹é‡å¤„ç†å™¨
    
    å°†å¤šä¸ªæ¶ˆæ¯æ‰¹é‡å¤„ç†ä»¥æé«˜æ€§èƒ½
    """
    
    def __init__(self, config: OptimizationConfig):
        self.config = config
        self.message_queue = asyncio.Queue()
        self.batch_buffer = []
        self.last_flush_time = time.time()
        self.is_running = False
        self.process_task = None
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_messages': 0,
            'total_batches': 0,
            'avg_batch_size': 0.0,
            'processing_time': 0.0
        }
    
    async def start(self):
        """å¯åŠ¨æ‰¹é‡å¤„ç†å™¨"""
        self.is_running = True
        self.process_task = asyncio.create_task(self._process_loop())
        logger.info("æ‰¹é‡å¤„ç†å™¨å·²å¯åŠ¨")
    
    async def stop(self):
        """åœæ­¢æ‰¹é‡å¤„ç†å™¨"""
        self.is_running = False
        
        if self.process_task:
            self.process_task.cancel()
            try:
                await self.process_task
            except asyncio.CancelledError:
                pass
        
        # å¤„ç†å‰©ä½™æ¶ˆæ¯
        if self.batch_buffer:
            await self._flush_batch()
        
        logger.info("æ‰¹é‡å¤„ç†å™¨å·²åœæ­¢")
    
    async def add_message(self, message: Dict[str, Any]):
        """æ·»åŠ æ¶ˆæ¯åˆ°æ‰¹é‡å¤„ç†é˜Ÿåˆ—
        
        Args:
            message: æ¶ˆæ¯å†…å®¹
        """
        await self.message_queue.put(message)
        self.stats['total_messages'] += 1
    
    async def _process_loop(self):
        """æ‰¹é‡å¤„ç†å¾ªç¯"""
        try:
            while self.is_running:
                try:
                    # ç­‰å¾…æ¶ˆæ¯æˆ–è¶…æ—¶
                    message = await asyncio.wait_for(
                        self.message_queue.get(), 
                        timeout=self.config.batch_timeout
                    )
                    
                    self.batch_buffer.append(message)
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°æ‰¹æ¬¡
                    if (len(self.batch_buffer) >= self.config.batch_size or
                        time.time() - self.last_flush_time >= self.config.batch_timeout):
                        await self._flush_batch()
                    
                except asyncio.TimeoutError:
                    # è¶…æ—¶ï¼Œåˆ·æ–°å½“å‰æ‰¹æ¬¡
                    if self.batch_buffer:
                        await self._flush_batch()
                    continue
                    
        except asyncio.CancelledError:
            logger.debug("æ‰¹é‡å¤„ç†å¾ªç¯è¢«å–æ¶ˆ")
        except Exception as e:
            logger.error(f"æ‰¹é‡å¤„ç†å¾ªç¯å‡ºé”™: {e}")
    
    async def _flush_batch(self):
        """åˆ·æ–°æ‰¹æ¬¡"""
        if not self.batch_buffer:
            return
        
        start_time = time.time()
        batch_size = len(self.batch_buffer)
        
        try:
            # å¤„ç†æ‰¹æ¬¡æ¶ˆæ¯
            await self._process_batch(self.batch_buffer.copy())
            
            # æ›´æ–°ç»Ÿè®¡
            processing_time = time.time() - start_time
            self.stats['total_batches'] += 1
            self.stats['processing_time'] += processing_time
            self.stats['avg_batch_size'] = (
                self.stats['total_messages'] / self.stats['total_batches']
            )
            
            logger.debug(f"å¤„ç†æ‰¹æ¬¡: {batch_size} æ¡æ¶ˆæ¯ï¼Œè€—æ—¶ {processing_time*1000:.2f}ms")
            
        except Exception as e:
            logger.error(f"æ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")
        finally:
            self.batch_buffer.clear()
            self.last_flush_time = time.time()
    
    async def _process_batch(self, messages: List[Dict[str, Any]]):
        """å¤„ç†æ‰¹æ¬¡æ¶ˆæ¯
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
        """
        # è¿™é‡Œå¯ä»¥å®ç°å…·ä½“çš„æ‰¹é‡å¤„ç†é€»è¾‘
        # ä¾‹å¦‚ï¼šæ‰¹é‡å†™å…¥æ•°æ®åº“ã€æ‰¹é‡å‘é€é€šçŸ¥ç­‰
        
        # ç¤ºä¾‹ï¼šæŒ‰æ¶ˆæ¯ç±»å‹åˆ†ç»„å¤„ç†
        message_groups = defaultdict(list)
        for message in messages:
            message_type = message.get('type', 'unknown')
            message_groups[message_type].append(message)
        
        # å¹¶è¡Œå¤„ç†ä¸åŒç±»å‹çš„æ¶ˆæ¯
        tasks = []
        for message_type, group_messages in message_groups.items():
            task = asyncio.create_task(
                self._process_message_group(message_type, group_messages)
            )
            tasks.append(task)
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
    
    async def _process_message_group(self, message_type: str, messages: List[Dict[str, Any]]):
        """å¤„ç†ç‰¹å®šç±»å‹çš„æ¶ˆæ¯ç»„
        
        Args:
            message_type: æ¶ˆæ¯ç±»å‹
            messages: æ¶ˆæ¯åˆ—è¡¨
        """
        # æ ¹æ®æ¶ˆæ¯ç±»å‹å®ç°ä¸åŒçš„å¤„ç†é€»è¾‘
        if message_type == 'market_data':
            await self._process_market_data_batch(messages)
        elif message_type == 'trade_data':
            await self._process_trade_data_batch(messages)
        else:
            logger.debug(f"å¤„ç† {len(messages)} æ¡ {message_type} æ¶ˆæ¯")
    
    async def _process_market_data_batch(self, messages: List[Dict[str, Any]]):
        """æ‰¹é‡å¤„ç†å¸‚åœºæ•°æ®"""
        # ç¤ºä¾‹ï¼šæ‰¹é‡æ›´æ–°ä»·æ ¼ç¼“å­˜
        logger.debug(f"æ‰¹é‡å¤„ç† {len(messages)} æ¡å¸‚åœºæ•°æ®")
    
    async def _process_trade_data_batch(self, messages: List[Dict[str, Any]]):
        """æ‰¹é‡å¤„ç†äº¤æ˜“æ•°æ®"""
        # ç¤ºä¾‹ï¼šæ‰¹é‡è®¡ç®—äº¤æ˜“ç»Ÿè®¡
        logger.debug(f"æ‰¹é‡å¤„ç† {len(messages)} æ¡äº¤æ˜“æ•°æ®")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–æ‰¹é‡å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.stats.copy()
        stats['queue_size'] = self.message_queue.qsize()
        stats['buffer_size'] = len(self.batch_buffer)
        return stats


class MemoryManager:
    """å†…å­˜ç®¡ç†å™¨
    
    ç›‘æ§å’Œä¼˜åŒ–å†…å­˜ä½¿ç”¨
    """
    
    def __init__(self, config: OptimizationConfig):
        self.config = config
        self.process = psutil.Process()
        self.gc_task = None
        self.is_running = False
        
        # å†…å­˜ç»Ÿè®¡
        self.memory_stats = {
            'peak_memory_mb': 0.0,
            'gc_collections': 0,
            'objects_collected': 0,
            'memory_warnings': 0
        }
    
    async def start(self):
        """å¯åŠ¨å†…å­˜ç®¡ç†å™¨"""
        self.is_running = True
        self.gc_task = asyncio.create_task(self._gc_loop())
        logger.info("å†…å­˜ç®¡ç†å™¨å·²å¯åŠ¨")
    
    async def stop(self):
        """åœæ­¢å†…å­˜ç®¡ç†å™¨"""
        self.is_running = False
        
        if self.gc_task:
            self.gc_task.cancel()
            try:
                await self.gc_task
            except asyncio.CancelledError:
                pass
        
        logger.info("å†…å­˜ç®¡ç†å™¨å·²åœæ­¢")
    
    def get_memory_usage(self) -> float:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
        try:
            memory_info = self.process.memory_info()
            memory_mb = memory_info.rss / 1024 / 1024
            
            # æ›´æ–°å³°å€¼å†…å­˜
            if memory_mb > self.memory_stats['peak_memory_mb']:
                self.memory_stats['peak_memory_mb'] = memory_mb
            
            return memory_mb
        except Exception as e:
            logger.error(f"è·å–å†…å­˜ä½¿ç”¨é‡å¤±è´¥: {e}")
            return 0.0
    
    def check_memory_threshold(self) -> bool:
        """æ£€æŸ¥å†…å­˜æ˜¯å¦è¶…è¿‡é˜ˆå€¼"""
        current_memory = self.get_memory_usage()
        
        if current_memory > self.config.memory_threshold_mb:
            self.memory_stats['memory_warnings'] += 1
            logger.warning(f"å†…å­˜ä½¿ç”¨é‡ {current_memory:.1f}MB è¶…è¿‡é˜ˆå€¼ {self.config.memory_threshold_mb}MB")
            return True
        
        return False
    
    async def _gc_loop(self):
        """åƒåœ¾å›æ”¶å¾ªç¯"""
        try:
            while self.is_running:
                await asyncio.sleep(self.config.gc_interval)
                
                if self.is_running:
                    await self._perform_gc()
                    
        except asyncio.CancelledError:
            logger.debug("åƒåœ¾å›æ”¶å¾ªç¯è¢«å–æ¶ˆ")
        except Exception as e:
            logger.error(f"åƒåœ¾å›æ”¶å¾ªç¯å‡ºé”™: {e}")
    
    async def _perform_gc(self):
        """æ‰§è¡Œåƒåœ¾å›æ”¶"""
        try:
            memory_before = self.get_memory_usage()
            
            # æ‰§è¡Œåƒåœ¾å›æ”¶
            collected = gc.collect()
            
            memory_after = self.get_memory_usage()
            memory_freed = memory_before - memory_after
            
            # æ›´æ–°ç»Ÿè®¡
            self.memory_stats['gc_collections'] += 1
            self.memory_stats['objects_collected'] += collected
            
            if memory_freed > 1.0:  # é‡Šæ”¾è¶…è¿‡1MBæ—¶è®°å½•æ—¥å¿—
                logger.info(f"åƒåœ¾å›æ”¶: é‡Šæ”¾ {memory_freed:.1f}MB å†…å­˜ï¼Œå›æ”¶ {collected} ä¸ªå¯¹è±¡")
            
            # æ£€æŸ¥å†…å­˜é˜ˆå€¼
            self.check_memory_threshold()
            
        except Exception as e:
            logger.error(f"åƒåœ¾å›æ”¶å¤±è´¥: {e}")
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """è·å–å†…å­˜ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.memory_stats.copy()
        stats['current_memory_mb'] = self.get_memory_usage()
        stats['memory_threshold_mb'] = self.config.memory_threshold_mb
        return stats


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨
    
    ç›‘æ§ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡å’ŒWebSocketæ€§èƒ½
    """
    
    def __init__(self, config: OptimizationConfig):
        self.config = config
        self.process = psutil.Process()
        self.metrics_history = deque(maxlen=1000)
        self.monitor_task = None
        self.is_running = False
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            'avg_cpu_percent': 0.0,
            'avg_memory_mb': 0.0,
            'peak_message_rate': 0.0,
            'avg_latency_ms': 0.0,
            'total_network_bytes': 0
        }
        
        # æ¶ˆæ¯ç»Ÿè®¡
        self.message_counter = 0
        self.last_message_count = 0
        self.last_metrics_time = time.time()
    
    async def start(self):
        """å¯åŠ¨æ€§èƒ½ç›‘æ§å™¨"""
        self.is_running = True
        self.monitor_task = asyncio.create_task(self._monitor_loop())
        logger.info("æ€§èƒ½ç›‘æ§å™¨å·²å¯åŠ¨")
    
    async def stop(self):
        """åœæ­¢æ€§èƒ½ç›‘æ§å™¨"""
        self.is_running = False
        
        if self.monitor_task:
            self.monitor_task.cancel()
            try:
                await self.monitor_task
            except asyncio.CancelledError:
                pass
        
        logger.info("æ€§èƒ½ç›‘æ§å™¨å·²åœæ­¢")
    
    def record_message(self):
        """è®°å½•æ¶ˆæ¯"""
        self.message_counter += 1
    
    def record_latency(self, latency_ms: float):
        """è®°å½•å»¶è¿Ÿ"""
        # æ›´æ–°å¹³å‡å»¶è¿Ÿ
        if self.performance_stats['avg_latency_ms'] == 0:
            self.performance_stats['avg_latency_ms'] = latency_ms
        else:
            self.performance_stats['avg_latency_ms'] = (
                self.performance_stats['avg_latency_ms'] * 0.9 + latency_ms * 0.1
            )
    
    async def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        try:
            while self.is_running:
                await asyncio.sleep(self.config.metrics_interval)
                
                if self.is_running:
                    await self._collect_metrics()
                    
        except asyncio.CancelledError:
            logger.debug("æ€§èƒ½ç›‘æ§å¾ªç¯è¢«å–æ¶ˆ")
        except Exception as e:
            logger.error(f"æ€§èƒ½ç›‘æ§å¾ªç¯å‡ºé”™: {e}")
    
    async def _collect_metrics(self):
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        try:
            current_time = time.time()
            
            # CPUä½¿ç”¨ç‡
            cpu_percent = self.process.cpu_percent()
            
            # å†…å­˜ä½¿ç”¨é‡
            memory_info = self.process.memory_info()
            memory_mb = memory_info.rss / 1024 / 1024
            
            # ç½‘ç»œIO
            net_io = psutil.net_io_counters()
            network_bytes_sent = net_io.bytes_sent if net_io else 0
            network_bytes_recv = net_io.bytes_recv if net_io else 0
            
            # æ¶ˆæ¯é€Ÿç‡
            time_diff = current_time - self.last_metrics_time
            message_diff = self.message_counter - self.last_message_count
            message_rate = message_diff / time_diff if time_diff > 0 else 0
            
            # åˆ›å»ºæ€§èƒ½æŒ‡æ ‡
            metrics = PerformanceMetrics(
                timestamp=datetime.now(),
                cpu_percent=cpu_percent,
                memory_mb=memory_mb,
                network_bytes_sent=network_bytes_sent,
                network_bytes_recv=network_bytes_recv,
                message_rate=message_rate,
                latency_ms=self.performance_stats['avg_latency_ms']
            )
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self.metrics_history.append(metrics)
            
            # æ›´æ–°ç»Ÿè®¡
            self._update_performance_stats(metrics)
            
            # æ›´æ–°è®¡æ•°å™¨
            self.last_message_count = self.message_counter
            self.last_metrics_time = current_time
            
            # è®°å½•æ€§èƒ½æ—¥å¿—
            if logger.isEnabledFor(logging.DEBUG):
                logger.debug(f"æ€§èƒ½æŒ‡æ ‡: CPU {cpu_percent:.1f}% | "
                           f"å†…å­˜ {memory_mb:.1f}MB | "
                           f"æ¶ˆæ¯é€Ÿç‡ {message_rate:.1f}/s | "
                           f"å»¶è¿Ÿ {metrics.latency_ms:.1f}ms")
            
        except Exception as e:
            logger.error(f"æ”¶é›†æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")
    
    def _update_performance_stats(self, metrics: PerformanceMetrics):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        # æ›´æ–°å¹³å‡å€¼
        if self.performance_stats['avg_cpu_percent'] == 0:
            self.performance_stats['avg_cpu_percent'] = metrics.cpu_percent
        else:
            self.performance_stats['avg_cpu_percent'] = (
                self.performance_stats['avg_cpu_percent'] * 0.9 + metrics.cpu_percent * 0.1
            )
        
        if self.performance_stats['avg_memory_mb'] == 0:
            self.performance_stats['avg_memory_mb'] = metrics.memory_mb
        else:
            self.performance_stats['avg_memory_mb'] = (
                self.performance_stats['avg_memory_mb'] * 0.9 + metrics.memory_mb * 0.1
            )
        
        # æ›´æ–°å³°å€¼
        if metrics.message_rate > self.performance_stats['peak_message_rate']:
            self.performance_stats['peak_message_rate'] = metrics.message_rate
        
        # æ›´æ–°ç½‘ç»œæ€»é‡
        self.performance_stats['total_network_bytes'] = (
            metrics.network_bytes_sent + metrics.network_bytes_recv
        )
    
    def get_current_metrics(self) -> Optional[PerformanceMetrics]:
        """è·å–å½“å‰æ€§èƒ½æŒ‡æ ‡"""
        return self.metrics_history[-1] if self.metrics_history else None
    
    def get_metrics_history(self, minutes: int = 60) -> List[PerformanceMetrics]:
        """è·å–æ€§èƒ½æŒ‡æ ‡å†å²
        
        Args:
            minutes: å†å²æ—¶é—´èŒƒå›´ï¼ˆåˆ†é’Ÿï¼‰
            
        Returns:
            List[PerformanceMetrics]: æ€§èƒ½æŒ‡æ ‡åˆ—è¡¨
        """
        cutoff_time = datetime.now() - timedelta(minutes=minutes)
        
        return [
            metrics for metrics in self.metrics_history
            if metrics.timestamp >= cutoff_time
        ]
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.performance_stats.copy()
        stats['total_messages'] = self.message_counter
        stats['metrics_collected'] = len(self.metrics_history)
        return stats
    
    def plot_performance_metrics(self, minutes: int = 30):
        """ç»˜åˆ¶æ€§èƒ½æŒ‡æ ‡å›¾è¡¨
        
        Args:
            minutes: æ—¶é—´èŒƒå›´ï¼ˆåˆ†é’Ÿï¼‰
        """
        history = self.get_metrics_history(minutes)
        
        if not history:
            logger.warning("æ²¡æœ‰æ€§èƒ½æŒ‡æ ‡æ•°æ®å¯ç»˜åˆ¶")
            return
        
        # æå–æ•°æ®
        timestamps = [m.timestamp for m in history]
        cpu_percents = [m.cpu_percent for m in history]
        memory_mbs = [m.memory_mb for m in history]
        message_rates = [m.message_rate for m in history]
        latencies = [m.latency_ms for m in history]
        
        # åˆ›å»ºå›¾è¡¨
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        # CPUä½¿ç”¨ç‡
        ax1.plot(timestamps, cpu_percents, 'b-', linewidth=2)
        ax1.set_title('CPU ä½¿ç”¨ç‡')
        ax1.set_ylabel('CPU %')
        ax1.grid(True, alpha=0.3)
        
        # å†…å­˜ä½¿ç”¨é‡
        ax2.plot(timestamps, memory_mbs, 'g-', linewidth=2)
        ax2.set_title('å†…å­˜ä½¿ç”¨é‡')
        ax2.set_ylabel('å†…å­˜ (MB)')
        ax2.grid(True, alpha=0.3)
        
        # æ¶ˆæ¯é€Ÿç‡
        ax3.plot(timestamps, message_rates, 'r-', linewidth=2)
        ax3.set_title('æ¶ˆæ¯é€Ÿç‡')
        ax3.set_ylabel('æ¶ˆæ¯/ç§’')
        ax3.grid(True, alpha=0.3)
        
        # å»¶è¿Ÿ
        ax4.plot(timestamps, latencies, 'm-', linewidth=2)
        ax4.set_title('å¹³å‡å»¶è¿Ÿ')
        ax4.set_ylabel('å»¶è¿Ÿ (ms)')
        ax4.grid(True, alpha=0.3)
        
        # æ ¼å¼åŒ–æ—¶é—´è½´
        for ax in [ax1, ax2, ax3, ax4]:
            ax.tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        plt.show()


class OptimizedWebSocketClient:
    """ä¼˜åŒ–çš„WebSocketå®¢æˆ·ç«¯
    
    é›†æˆæ‰€æœ‰æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½
    """
    
    def __init__(self, 
                 uri: str = "ws://localhost:8765",
                 config: OptimizationConfig = None):
        """åˆå§‹åŒ–ä¼˜åŒ–å®¢æˆ·ç«¯
        
        Args:
            uri: WebSocketæœåŠ¡åœ°å€
            config: ä¼˜åŒ–é…ç½®
        """
        self.uri = uri
        self.config = config or OptimizationConfig()
        self.client_id = f"optimized_client_{int(time.time())}"
        
        # WebSocketè¿æ¥
        self.websocket = None
        self.is_connected = False
        self.is_running = False
        
        # ä¼˜åŒ–ç»„ä»¶
        self.compression_manager = CompressionManager(self.config)
        self.batch_processor = BatchProcessor(self.config)
        self.memory_manager = MemoryManager(self.config)
        self.performance_monitor = PerformanceMonitor(self.config)
        
        # æ•°æ®å­˜å‚¨ï¼ˆä½¿ç”¨é«˜æ•ˆçš„æ•°æ®ç»“æ„ï¼‰
        self.message_cache = deque(maxlen=self.config.max_message_history)
        self.subscription_cache = {}
        
        # å¼‚æ­¥ä»»åŠ¡
        self.receive_task = None
        self.heartbeat_task = None
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.client_stats = {
            'start_time': None,
            'messages_sent': 0,
            'messages_received': 0,
            'bytes_sent': 0,
            'bytes_received': 0,
            'compression_enabled': self.config.enable_compression,
            'batch_processing_enabled': True
        }
    
    async def start(self):
        """å¯åŠ¨ä¼˜åŒ–å®¢æˆ·ç«¯"""
        logger.info("ğŸš€ å¯åŠ¨ä¼˜åŒ–WebSocketå®¢æˆ·ç«¯")
        
        try:
            # å¯åŠ¨ä¼˜åŒ–ç»„ä»¶
            await self.batch_processor.start()
            await self.memory_manager.start()
            await self.performance_monitor.start()
            
            # è¿æ¥WebSocket
            await self._connect()
            
            self.client_stats['start_time'] = datetime.now()
            logger.info("âœ… ä¼˜åŒ–å®¢æˆ·ç«¯å¯åŠ¨æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"å¯åŠ¨ä¼˜åŒ–å®¢æˆ·ç«¯å¤±è´¥: {e}")
            await self.stop()
            raise
    
    async def stop(self):
        """åœæ­¢ä¼˜åŒ–å®¢æˆ·ç«¯"""
        logger.info("â¹ï¸ åœæ­¢ä¼˜åŒ–WebSocketå®¢æˆ·ç«¯")
        
        self.is_running = False
        self.is_connected = False
        
        # åœæ­¢å¼‚æ­¥ä»»åŠ¡
        tasks = [self.receive_task, self.heartbeat_task]
        for task in tasks:
            if task and not task.done():
                task.cancel()
                try:
                    await task
                except asyncio.CancelledError:
                    pass
        
        # å…³é—­WebSocketè¿æ¥
        if self.websocket:
            await self.websocket.close()
        
        # åœæ­¢ä¼˜åŒ–ç»„ä»¶
        await self.batch_processor.stop()
        await self.memory_manager.stop()
        await self.performance_monitor.stop()
        
        logger.info("ä¼˜åŒ–å®¢æˆ·ç«¯å·²åœæ­¢")
    
    async def _connect(self):
        """è¿æ¥WebSocketæœåŠ¡å™¨"""
        try:
            logger.info(f"è¿æ¥åˆ° {self.uri}")
            
            # ä½¿ç”¨ä¼˜åŒ–çš„è¿æ¥å‚æ•°
            self.websocket = await websockets.connect(
                self.uri,
                ping_interval=self.config.ping_interval,
                ping_timeout=self.config.ping_timeout,
                max_size=2**20,  # 1MB
                max_queue=2**5,  # 32
                compression=None  # ä½¿ç”¨è‡ªå®šä¹‰å‹ç¼©
            )
            
            self.is_connected = True
            self.is_running = True
            
            # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡
            self.receive_task = asyncio.create_task(self._receive_loop())
            self.heartbeat_task = asyncio.create_task(self._heartbeat_loop())
            
            logger.info("WebSocketè¿æ¥æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"WebSocketè¿æ¥å¤±è´¥: {e}")
            raise
    
    async def _receive_loop(self):
        """æ¶ˆæ¯æ¥æ”¶å¾ªç¯"""
        try:
            while self.is_running and self.websocket:
                try:
                    # æ¥æ”¶æ¶ˆæ¯
                    raw_message = await asyncio.wait_for(
                        self.websocket.recv(), timeout=1.0
                    )
                    
                    # è®°å½•æ€§èƒ½æŒ‡æ ‡
                    self.performance_monitor.record_message()
                    
                    # å¤„ç†æ¶ˆæ¯
                    await self._handle_raw_message(raw_message)
                    
                    # æ›´æ–°ç»Ÿè®¡
                    self.client_stats['messages_received'] += 1
                    if isinstance(raw_message, bytes):
                        self.client_stats['bytes_received'] += len(raw_message)
                    else:
                        self.client_stats['bytes_received'] += len(raw_message.encode('utf-8'))
                    
                except asyncio.TimeoutError:
                    continue
                except Exception as e:
                    logger.error(f"æ¥æ”¶æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
                    break
                    
        except asyncio.CancelledError:
            logger.debug("æ¶ˆæ¯æ¥æ”¶å¾ªç¯è¢«å–æ¶ˆ")
        except Exception as e:
            logger.error(f"æ¶ˆæ¯æ¥æ”¶å¾ªç¯å‡ºé”™: {e}")
        finally:
            self.is_connected = False
    
    async def _handle_raw_message(self, raw_message):
        """å¤„ç†åŸå§‹æ¶ˆæ¯"""
        try:
            # è§£å‹æ¶ˆæ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if isinstance(raw_message, bytes):
                try:
                    message_str = self.compression_manager.decompress_data(raw_message)
                except:
                    message_str = raw_message.decode('utf-8')
            else:
                message_str = raw_message
            
            # è§£æJSON
            message = json.loads(message_str)
            
            # æ·»åŠ åˆ°æ‰¹é‡å¤„ç†å™¨
            await self.batch_processor.add_message(message)
            
            # æ·»åŠ åˆ°æ¶ˆæ¯ç¼“å­˜
            self.message_cache.append({
                'timestamp': datetime.now(),
                'message': message
            })
            
            # å¤„ç†ç‰¹å®šç±»å‹çš„æ¶ˆæ¯
            await self._handle_message(message)
            
        except Exception as e:
            logger.error(f"å¤„ç†åŸå§‹æ¶ˆæ¯å¤±è´¥: {e}")
    
    async def _handle_message(self, message: Dict[str, Any]):
        """å¤„ç†è§£æåçš„æ¶ˆæ¯"""
        message_type = message.get("type", "unknown")
        
        if message_type == "market_data":
            await self._handle_market_data(message.get("data", {}))
        elif message_type == "heartbeat":
            await self._handle_heartbeat_response(message.get("data", {}))
        # æ·»åŠ å…¶ä»–æ¶ˆæ¯ç±»å‹å¤„ç†...
    
    async def _handle_market_data(self, data: Dict[str, Any]):
        """å¤„ç†å¸‚åœºæ•°æ®"""
        symbol = data.get("symbol", "")
        price = data.get("last_price", 0)
        
        # è®°å½•å»¶è¿Ÿï¼ˆå¦‚æœæœ‰æ—¶é—´æˆ³ï¼‰
        if "timestamp" in data:
            try:
                server_time = datetime.fromisoformat(data["timestamp"])
                latency = (datetime.now() - server_time).total_seconds() * 1000
                self.performance_monitor.record_latency(latency)
            except:
                pass
        
        logger.debug(f"ğŸ“ˆ {symbol}: Â¥{price}")
    
    async def _handle_heartbeat_response(self, data: Dict[str, Any]):
        """å¤„ç†å¿ƒè·³å“åº”"""
        server_time = data.get("server_time")
        if server_time:
            try:
                server_dt = datetime.fromisoformat(server_time)
                latency = (datetime.now() - server_dt).total_seconds() * 1000
                self.performance_monitor.record_latency(latency)
            except:
                pass
    
    async def _heartbeat_loop(self):
        """å¿ƒè·³å¾ªç¯"""
        try:
            while self.is_running and self.is_connected:
                await asyncio.sleep(30)  # æ¯30ç§’å‘é€å¿ƒè·³
                
                if self.is_running and self.is_connected:
                    await self._send_heartbeat()
                    
        except asyncio.CancelledError:
            logger.debug("å¿ƒè·³å¾ªç¯è¢«å–æ¶ˆ")
        except Exception as e:
            logger.error(f"å¿ƒè·³å¾ªç¯å‡ºé”™: {e}")
    
    async def _send_heartbeat(self):
        """å‘é€å¿ƒè·³"""
        try:
            heartbeat_msg = {
                "type": "heartbeat",
                "data": {
                    "client_time": datetime.now().isoformat(),
                    "client_id": self.client_id
                }
            }
            
            await self.send_message(heartbeat_msg)
            
        except Exception as e:
            logger.error(f"å‘é€å¿ƒè·³å¤±è´¥: {e}")
    
    async def send_message(self, message: Dict[str, Any]):
        """å‘é€æ¶ˆæ¯ï¼ˆå¸¦ä¼˜åŒ–ï¼‰
        
        Args:
            message: æ¶ˆæ¯å†…å®¹
        """
        if not self.is_connected or not self.websocket:
            logger.error("WebSocketæœªè¿æ¥ï¼Œæ— æ³•å‘é€æ¶ˆæ¯")
            return
        
        try:
            # åºåˆ—åŒ–æ¶ˆæ¯
            message_str = json.dumps(message)
            
            # å‹ç¼©æ¶ˆæ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.config.enable_compression:
                message_data = self.compression_manager.compress_data(message_str)
            else:
                message_data = message_str
            
            # å‘é€æ¶ˆæ¯
            await self.websocket.send(message_data)
            
            # æ›´æ–°ç»Ÿè®¡
            self.client_stats['messages_sent'] += 1
            if isinstance(message_data, bytes):
                self.client_stats['bytes_sent'] += len(message_data)
            else:
                self.client_stats['bytes_sent'] += len(message_data.encode('utf-8'))
            
        except Exception as e:
            logger.error(f"å‘é€æ¶ˆæ¯å¤±è´¥: {e}")
    
    async def subscribe(self, symbol: str, data_type: str = "quote"):
        """è®¢é˜…æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data_type: æ•°æ®ç±»å‹
        """
        subscription_request = {
            "type": "subscribe",
            "data": {
                "symbol": symbol,
                "data_type": data_type,
                "client_id": self.client_id
            }
        }
        
        await self.send_message(subscription_request)
        
        # ç¼“å­˜è®¢é˜…ä¿¡æ¯
        subscription_key = f"{symbol}_{data_type}"
        self.subscription_cache[subscription_key] = {
            "symbol": symbol,
            "data_type": data_type,
            "subscribed_at": datetime.now()
        }
        
        logger.info(f"å·²è®¢é˜…: {symbol} ({data_type})")
    
    def get_optimization_stats(self) -> Dict[str, Any]:
        """è·å–ä¼˜åŒ–ç»Ÿè®¡ä¿¡æ¯"""
        uptime = None
        if self.client_stats['start_time']:
            uptime = str(datetime.now() - self.client_stats['start_time'])
        
        return {
            'client_stats': {
                **self.client_stats,
                'uptime': uptime,
                'is_connected': self.is_connected,
                'subscriptions_count': len(self.subscription_cache),
                'message_cache_size': len(self.message_cache)
            },
            'compression_stats': self.compression_manager.get_compression_stats(),
            'batch_processing_stats': self.batch_processor.get_stats(),
            'memory_stats': self.memory_manager.get_memory_stats(),
            'performance_stats': self.performance_monitor.get_performance_stats()
        }
    
    def plot_performance_metrics(self, minutes: int = 30):
        """ç»˜åˆ¶æ€§èƒ½æŒ‡æ ‡å›¾è¡¨"""
        self.performance_monitor.plot_performance_metrics(minutes)


async def demo_basic_optimization():
    """åŸºæœ¬ä¼˜åŒ–æ¼”ç¤º"""
    print("ğŸš€ WebSocket åŸºæœ¬æ€§èƒ½ä¼˜åŒ–æ¼”ç¤º")
    
    # åˆ›å»ºä¼˜åŒ–é…ç½®
    config = OptimizationConfig(
        enable_compression=True,
        compression_threshold=512,
        batch_size=50,
        batch_timeout=0.2,
        max_message_history=5000,
        memory_threshold_mb=256.0
    )
    
    # åˆ›å»ºä¼˜åŒ–å®¢æˆ·ç«¯
    client = OptimizedWebSocketClient(
        uri="ws://localhost:8765",
        config=config
    )
    
    try:
        # å¯åŠ¨å®¢æˆ·ç«¯
        await client.start()
        
        # è®¢é˜…æ•°æ®
        print("ğŸ“¡ è®¢é˜…å®æ—¶æ•°æ®...")
        await client.subscribe("000001.SZ", "quote")
        await client.subscribe("600519.SH", "quote")
        
        # è¿è¡Œ60ç§’
        print("â° è¿è¡Œ60ç§’ï¼Œè§‚å¯Ÿä¼˜åŒ–æ•ˆæœ...")
        await asyncio.sleep(60)
        
        # è·å–ä¼˜åŒ–ç»Ÿè®¡
        stats = client.get_optimization_stats()
        
        print(f"\nğŸ“Š ä¼˜åŒ–ç»Ÿè®¡:")
        print(f"   è¿è¡Œæ—¶é•¿: {stats['client_stats']['uptime']}")
        print(f"   æ¥æ”¶æ¶ˆæ¯: {stats['client_stats']['messages_received']}")
        print(f"   å‘é€æ¶ˆæ¯: {stats['client_stats']['messages_sent']}")
        print(f"   æ¥æ”¶å­—èŠ‚: {stats['client_stats']['bytes_received']:,}")
        print(f"   å‘é€å­—èŠ‚: {stats['client_stats']['bytes_sent']:,}")
        
        # å‹ç¼©ç»Ÿè®¡
        compression_stats = stats['compression_stats']
        print(f"\nğŸ—œï¸ å‹ç¼©ç»Ÿè®¡:")
        print(f"   å‹ç¼©æ¬¡æ•°: {compression_stats['total_compressed']}")
        print(f"   å‹ç¼©æ¯”: {compression_stats['compression_ratio']:.1f}%")
        print(f"   å¹³å‡å‹ç¼©æ—¶é—´: {compression_stats['avg_compression_time']*1000:.2f}ms")
        
        # æ‰¹å¤„ç†ç»Ÿè®¡
        batch_stats = stats['batch_processing_stats']
        print(f"\nğŸ“¦ æ‰¹å¤„ç†ç»Ÿè®¡:")
        print(f"   å¤„ç†æ‰¹æ¬¡: {batch_stats['total_batches']}")
        print(f"   å¹³å‡æ‰¹æ¬¡å¤§å°: {batch_stats['avg_batch_size']:.1f}")
        print(f"   å¤„ç†æ—¶é—´: {batch_stats['processing_time']*1000:.2f}ms")
        
        # å†…å­˜ç»Ÿè®¡
        memory_stats = stats['memory_stats']
        print(f"\nğŸ’¾ å†…å­˜ç»Ÿè®¡:")
        print(f"   å½“å‰å†…å­˜: {memory_stats['current_memory_mb']:.1f}MB")
        print(f"   å³°å€¼å†…å­˜: {memory_stats['peak_memory_mb']:.1f}MB")
        print(f"   åƒåœ¾å›æ”¶: {memory_stats['gc_collections']} æ¬¡")
        
        # æ€§èƒ½ç»Ÿè®¡
        performance_stats = stats['performance_stats']
        print(f"\nâš¡ æ€§èƒ½ç»Ÿè®¡:")
        print(f"   å¹³å‡CPU: {performance_stats['avg_cpu_percent']:.1f}%")
        print(f"   å¹³å‡å†…å­˜: {performance_stats['avg_memory_mb']:.1f}MB")
        print(f"   å³°å€¼æ¶ˆæ¯é€Ÿç‡: {performance_stats['peak_message_rate']:.1f}/s")
        print(f"   å¹³å‡å»¶è¿Ÿ: {performance_stats['avg_latency_ms']:.1f}ms")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
    finally:
        await client.stop()


async def demo_performance_comparison():
    """æ€§èƒ½å¯¹æ¯”æ¼”ç¤º"""
    print("ğŸ¯ WebSocket æ€§èƒ½å¯¹æ¯”æ¼”ç¤º")
    
    # åˆ›å»ºä¸¤ä¸ªå®¢æˆ·ç«¯ï¼šä¼˜åŒ–ç‰ˆå’Œæ™®é€šç‰ˆ
    optimized_config = OptimizationConfig(
        enable_compression=True,
        batch_size=100,
        batch_timeout=0.1,
        memory_threshold_mb=256.0
    )
    
    basic_config = OptimizationConfig(
        enable_compression=False,
        batch_size=1,  # ä¸ä½¿ç”¨æ‰¹å¤„ç†
        batch_timeout=1.0,
        memory_threshold_mb=1024.0
    )
    
    optimized_client = OptimizedWebSocketClient(
        uri="ws://localhost:8765",
        config=optimized_config
    )
    
    basic_client = OptimizedWebSocketClient(
        uri="ws://localhost:8765", 
        config=basic_config
    )
    
    try:
        print("ğŸš€ å¯åŠ¨ä¸¤ä¸ªå®¢æˆ·ç«¯è¿›è¡Œæ€§èƒ½å¯¹æ¯”...")
        
        # å¯åŠ¨å®¢æˆ·ç«¯
        await optimized_client.start()
        await basic_client.start()
        
        # è®¢é˜…ç›¸åŒçš„æ•°æ®
        symbols = ["000001.SZ", "600519.SH", "000002.SZ"]
        
        for symbol in symbols:
            await optimized_client.subscribe(symbol, "quote")
            await basic_client.subscribe(symbol, "quote")
        
        # è¿è¡Œæµ‹è¯•
        print("â° è¿è¡Œ90ç§’æ€§èƒ½å¯¹æ¯”æµ‹è¯•...")
        await asyncio.sleep(90)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        optimized_stats = optimized_client.get_optimization_stats()
        basic_stats = basic_client.get_optimization_stats()
        
        print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”ç»“æœ:")
        print(f"{'æŒ‡æ ‡':<20} {'ä¼˜åŒ–ç‰ˆ':<15} {'æ™®é€šç‰ˆ':<15} {'æå‡':<10}")
        print("-" * 65)
        
        # æ¶ˆæ¯å¤„ç†æ€§èƒ½
        opt_msg_rate = optimized_stats['performance_stats']['peak_message_rate']
        basic_msg_rate = basic_stats['performance_stats']['peak_message_rate']
        msg_improvement = (opt_msg_rate / basic_msg_rate - 1) * 100 if basic_msg_rate > 0 else 0
        
        print(f"{'æ¶ˆæ¯é€Ÿç‡(/s)':<20} {opt_msg_rate:<15.1f} {basic_msg_rate:<15.1f} {msg_improvement:+.1f}%")
        
        # å†…å­˜ä½¿ç”¨
        opt_memory = optimized_stats['memory_stats']['peak_memory_mb']
        basic_memory = basic_stats['memory_stats']['peak_memory_mb']
        memory_improvement = (1 - opt_memory / basic_memory) * 100 if basic_memory > 0 else 0
        
        print(f"{'å³°å€¼å†…å­˜(MB)':<20} {opt_memory:<15.1f} {basic_memory:<15.1f} {memory_improvement:+.1f}%")
        
        # CPUä½¿ç”¨ç‡
        opt_cpu = optimized_stats['performance_stats']['avg_cpu_percent']
        basic_cpu = basic_stats['performance_stats']['avg_cpu_percent']
        cpu_improvement = (1 - opt_cpu / basic_cpu) * 100 if basic_cpu > 0 else 0
        
        print(f"{'å¹³å‡CPU(%)':<20} {opt_cpu:<15.1f} {basic_cpu:<15.1f} {cpu_improvement:+.1f}%")
        
        # ç½‘ç»œä½¿ç”¨
        opt_bytes = optimized_stats['client_stats']['bytes_received']
        basic_bytes = basic_stats['client_stats']['bytes_received']
        bytes_improvement = (1 - opt_bytes / basic_bytes) * 100 if basic_bytes > 0 else 0
        
        print(f"{'ç½‘ç»œæ¥æ”¶(å­—èŠ‚)':<20} {opt_bytes:<15,} {basic_bytes:<15,} {bytes_improvement:+.1f}%")
        
        # å»¶è¿Ÿ
        opt_latency = optimized_stats['performance_stats']['avg_latency_ms']
        basic_latency = basic_stats['performance_stats']['avg_latency_ms']
        latency_improvement = (1 - opt_latency / basic_latency) * 100 if basic_latency > 0 else 0
        
        print(f"{'å¹³å‡å»¶è¿Ÿ(ms)':<20} {opt_latency:<15.1f} {basic_latency:<15.1f} {latency_improvement:+.1f}%")
        
        # å‹ç¼©æ•ˆæœ
        compression_stats = optimized_stats['compression_stats']
        if compression_stats['total_compressed'] > 0:
            print(f"\nğŸ—œï¸ å‹ç¼©æ•ˆæœ:")
            print(f"   å‹ç¼©æ¯”: {compression_stats['compression_ratio']:.1f}%")
            print(f"   èŠ‚çœå¸¦å®½: {compression_stats['total_original_size'] - compression_stats['total_compressed_size']:,} å­—èŠ‚")
        
        # ç»˜åˆ¶æ€§èƒ½å›¾è¡¨
        print(f"\nğŸ“ˆ ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨...")
        try:
            optimized_client.plot_performance_metrics(minutes=30)
        except Exception as e:
            print(f"ç»˜åˆ¶å›¾è¡¨å¤±è´¥: {e}")
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½å¯¹æ¯”æ¼”ç¤ºå‡ºé”™: {e}")
    finally:
        await optimized_client.stop()
        await basic_client.stop()


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“ WebSocket æ€§èƒ½ä¼˜åŒ–å’Œæœ€ä½³å®è·µæ•™ç¨‹")
    print("æœ¬æ•™ç¨‹å±•ç¤ºå¦‚ä½•ä¼˜åŒ– WebSocket å®æ—¶æ•°æ®ç³»ç»Ÿçš„æ€§èƒ½")
    
    # æ£€æŸ¥WebSocketæœåŠ¡è¿æ¥
    try:
        test_websocket = await websockets.connect("ws://localhost:8765", ping_timeout=5)
        await test_websocket.close()
        print("âœ… WebSocket æœåŠ¡è¿æ¥æ­£å¸¸")
    except Exception as e:
        print("âŒ æ— æ³•è¿æ¥åˆ° WebSocket æœåŠ¡å™¨")
        print("è¯·ç¡®ä¿æœåŠ¡å™¨å·²å¯åŠ¨ï¼špython -m src.argus_mcp.websocket_server")
        return
    
    # è®¾ç½®é«˜æ€§èƒ½äº‹ä»¶å¾ªç¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    try:
        import uvloop
        asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
        print("âœ… ä½¿ç”¨ uvloop é«˜æ€§èƒ½äº‹ä»¶å¾ªç¯")
    except ImportError:
        print("â„¹ï¸ æœªå®‰è£… uvloopï¼Œä½¿ç”¨é»˜è®¤äº‹ä»¶å¾ªç¯")
    
    try:
        # è¿è¡ŒåŸºæœ¬ä¼˜åŒ–æ¼”ç¤º
        await demo_basic_optimization()
        
        print("\n" + "="*60)
        input("æŒ‰ Enter é”®ç»§ç»­æ€§èƒ½å¯¹æ¯”æ¼”ç¤º...")
        
        # è¿è¡Œæ€§èƒ½å¯¹æ¯”æ¼”ç¤º
        await demo_performance_comparison()
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æ•™ç¨‹è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ æ•™ç¨‹è¿è¡Œå‡ºé”™: {e}")
    
    print("\nğŸ‰ WebSocket æ€§èƒ½ä¼˜åŒ–æ•™ç¨‹å®Œæˆï¼")
    print("\nğŸ“š ä¼˜åŒ–è¦ç‚¹æ€»ç»“ï¼š")
    print("1. æ•°æ®å‹ç¼© - å‡å°‘ç½‘ç»œä¼ è¾“é‡")
    print("2. æ‰¹é‡å¤„ç† - æé«˜æ¶ˆæ¯å¤„ç†æ•ˆç‡")
    print("3. å†…å­˜ç®¡ç† - æ§åˆ¶å†…å­˜ä½¿ç”¨å’Œåƒåœ¾å›æ”¶")
    print("4. æ€§èƒ½ç›‘æ§ - å®æ—¶ç›‘æ§ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡")
    print("5. è¿æ¥ä¼˜åŒ– - ä¼˜åŒ–è¿æ¥å‚æ•°å’Œå¿ƒè·³æœºåˆ¶")
    print("6. å¼‚æ­¥å¤„ç† - å……åˆ†åˆ©ç”¨å¼‚æ­¥IOä¼˜åŠ¿")
    print("\nğŸ’¡ æœ€ä½³å®è·µå»ºè®®ï¼š")
    print("- æ ¹æ®æ•°æ®ç‰¹ç‚¹é€‰æ‹©åˆé€‚çš„å‹ç¼©ç®—æ³•")
    print("- åˆç†è®¾ç½®æ‰¹å¤„ç†å¤§å°å’Œè¶…æ—¶æ—¶é—´")
    print("- å®šæœŸç›‘æ§å†…å­˜ä½¿ç”¨å’Œæ€§èƒ½æŒ‡æ ‡")
    print("- å®ç°ä¼˜é›…çš„é”™è¯¯å¤„ç†å’Œé‡è¿æœºåˆ¶")
    print("- åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨é«˜æ€§èƒ½äº‹ä»¶å¾ªç¯")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ•™ç¨‹ç»“æŸ")
    except Exception as e:
        logger.error(f"æ•™ç¨‹è¿è¡Œå¤±è´¥: {e}")
        sys.exit(1)
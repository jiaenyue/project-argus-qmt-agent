
# Project Argus: 天枢计划

## 项目用户故事全集 (V4.0 - 完整交付版)

### 项目角色 (Personas)

*   **量化分析师 (Quantitative Analyst):** 数据的最终用户，追求数据的准确性、完整性、多维度和易用性，以构建可靠的交易策略。
*   **数据工程师 (Data Engineer):** 数据管道的建设者，关注数据流的效率、代码的健壮性和数据模型的正确性。
*   **数据质量分析师 (DQA):** 数据的守护者，专注于定义、实施和监控数据质量标准，是数据可信度的最终负责人。
*   **DevOps工程师 / 运维工程师 (DevOps Engineer):** 系统的运维者，负责部署、自动化、监控和容灾，保障系统稳定运行。
*   **项目经理 / 安全官 (PM / Security Officer):** 项目的管理者，关注范围、风险、合规性与成本。

---

### Epic 1: 核心数据采集与基础处理
**目标:** 建立稳定、解耦、标准化的原始数据采集与缓冲流程，为高质量数据处理奠定基础。
**可交付成果:** 一个可独立运行的数据采集服务，能自动从`miniQMT`获取数据，将其作为标准事件保存到本地文件队列，并由一个基础处理器读取和格式化。团队可以演示从数据源到`Bronze`层的完整、自动化的数据流。

*   **故事 1.1: 主数据源行情采集 (通过Windows数据代理)**
    *   **作为** 一名数据工程师，
    *   **我想要** 系统能通过部署在Windows上的`QMT数据代理`，稳定采集主数据源`miniQMT`的A股市场日线和分钟线行情，
    *   **以便** 在解耦Windows依赖的同时，为整个数据管道提供基础的、高优先级的原始行情数据。
    *   **验收标准:**
        1.  `qmt_collector.py`能够通过HTTP(S)成功调用`Windows QMT数据代理`暴露的API。
        2.  通过代理采集的数据能够成功获取99.5%以上交易日的行情数据 (`FR-001`)。
        3.  采集任务支持按天执行。
        4.  `qmt_collector.py`和`Windows QMT数据代理`都能处理基本的网络异常并进行有限次重试和记录日志。
        5.  `Windows QMT数据代理`在Windows上稳定运行，并能正确连接本地miniQMT。

*   **故事 1.2: 事件驱动的弹性采集架构**
    *   **作为** 一名系统架构师，
    *   **我想要** 通过本地文件队列作为中央消息总线来解耦数据采集与处理层，
    *   **以便** 提升系统韧性，支持削峰填谷，并为未来向实时处理演进提供扩展能力 (`system_design.md`)。
    *   **验收标准:**
        1.  所有从数据源采集的原始数据，都被封装为标准事件并保存到本地文件队列。
        2.  事件包含来源、采集时间戳等关键元数据。
        3.  本地文件队列配置了适当的持久化策略，确保数据在下游服务不可用时不会丢失。

*   **故事 1.3: Bronze层数据标准化**
    *   **作为** 一名数据工程师，
    *   **我想要** 实现一个读取本地文件队列原始数据的`Bronze`层处理器，
    *   **以便** 对来自不同源头的数据进行统一的格式化、去重和基础类型转换，为后续处理奠定干净的数据基础。
    *   **验收标准:**
        1.  处理器能正确消费`raw_data_topic`中的消息。
        2.  输出的数据中，日期字段统一为`YYYY-MM-DD`格式，股票代码统一为`XXXXXX.SH/SZ`格式。
        3.  重复的原始记录（基于唯一键）被识别并剔除，确保Silver层输入无重复 (`FR-003`)。

*   **故事 1.4: 编排自动化采集工作流**
    *   **作为** 一名数据工程师，
    *   **我想要** 创建一个端到端的Windows任务调度工作流，
    *   **以便** 自动化地调度和监控从数据采集到`Bronze`层处理的全过程，实现无人值守的日常数据注入。
    *   **验收标准:**
        1.  一个名为`qmt_to_bronze_pipeline`的Windows任务调度被创建并纳入代码库 (`TR-003`)。
        2.  该DAG按`@daily`计划自动运行，并能手动触发以供演示和测试 (`FR-010`)。
        3.  DAG中的任务（如`collect_from_qmt`和`process_to_bronze`）按正确的依赖关系执行。
        4.  每个任务都配置了失败重试策略（例如，重试3次，间隔5分钟）。
        5.  任务的执行状态（成功、运行中、失败）在Windows事件日志中清晰可见，便于监控和故障排查。

---

### Epic 2: Tushare深度集成与多源数据融合
**目标:** 深度集成`Tushare Pro`作为补充和备份数据源，构建智能融合引擎，极大丰富数据维度和准确性。
**可交付成果:** 一个增强版的数据处理服务，能同时处理来自`miniQMT`和`Tushare`的数据。团队可以演示：1) 从Tushare获取财务数据；2) 融合引擎根据`data_governance`规则自动解决冲突；3) 配额不足时系统如何自动告警和熔断；4) 数据在融合前已完成精确的时间轴对齐。

*   **故事 2.1: Tushare多维度数据赋能**
    *   **作为** 一名量化分析师，
    *   **我想要** 系统能够从`Tushare Pro`获取财务指标（PE/PB）、公司行动（分红/拆股）和分析师评级数据，
    *   **以便** 我可以构建更复杂的多因子模型和事件驱动策略，捕捉更多套利机会。
    *   **验收标准:**
        1.  Tushare数据采集API的调用成功率 > 99.5% (`FR-002`)。
        2.  最终Gold层数据包含`pe_ttm`, `pb_mrq`, `div_cash`, `analyst_rating`等关键补充字段。
        3.  采集到的数据同样被发布到数据缓存中，供下游消费。

*   **故事 2.2: 遵循治理原则的智能融合**
    *   **作为** 一名数据工程师，
    *   **我想要** 开发一个遵循“数据源优先级原则”的智能数据融合引擎，
    *   **以便** 能自动、正确地合并`miniQMT`和`Tushare Pro`的数据，并记录完整的数据血缘。
    *   **验收标准:**
        1.  引擎严格遵循`data_governance`文档中定义的优先级：行情数据`miniQMT > Tushare`，财务数据`Tushare > miniQMT` (`FR-004`)。
        2.  当主数据源数据有效时，必须采用主数据源的数据。
        3.  融合后的每个关键字段都必须有一个伴随的`_source`字段，明确标明其来源 (`FR-004`, `data_governance_and_dictionary.md`)。

*   **故事 2.3: 基于模型的智能缺失值处理**
    *   **作为** 一名数据工程师，
    *   **我想要** 当核心字段（如收盘价）在所有源中都缺失时，系统能自动触发`Prophet`等机器学习模型进行预测填补，
    *   **以便** 最大化数据完整性，并能在数据缺失率超过1%时立即发出P0级告警 (`quality_kpi.md`, `data_governance_and_dictionary.md`)。
    *   **验收标准:**
        1.  系统实现了基于时间序列模型的预测填补能力 (`FR-006`)。
        2.  当关键字段处理后缺失率超过1%时，会触发最高级别告警，并可能中断数据发布。
        3.  关键数值字段的最终缺失率在处理后低于0.1%。

*   **故事 2.4: Tushare配额熔断机制**
    *   **作为** 一名DevOps工程师，
    *   **我想要** 一个基于内存缓存的Tushare配额管理器，它能在配额即将耗尽时触发熔断，
    *   **以便** 主动避免因配额耗尽导致核心管道中断，保障数据供应的连续性 (`FR-009`, `risk_register: DATA-02`)。
    *   **验收标准:**
        1.  当配额使用率超过90%时，系统自动触发P1级告警。
        2.  当配额耗尽时，针对行情数据的采集会自动切换为仅使用`miniQMT`（熔断切换）。
        3.  针对补充数据的采集任务则会自动熔断（暂停），防止产生不完整数据。

*   **故事 2.5: 实现多源数据时间轴对齐**
    *   **作为** 一名数据工程师，
    *   **我想要** 在执行数据融合前，系统能自动将来自`miniQMT`和`Tushare`的数据在时间轴上精确对齐，
    *   **以便** 确保后续的冲突解决和字段合并是在同一交易日的数据上进行的，保证融合的正确性。
    *   **验收标准:**
        1.  该步骤是`Silver Processor`中的一个明确阶段 (`FR-005`)。
        2.  所有时间序列数据（如K线、财务报告日）能精确对齐到交易日。
        3.  处理逻辑能正确处理一个源有数据而另一个源没有的情况（例如，新股上市或停牌日）。

---

### Epic 3: 黄金标准数据发布与消费
**目标:** 以工业级标准发布可信、高性能、即用型的数据，赋能下游量化策略。
**可交付成果:** 完整的Gold层数据存储。团队可以演示：1) 最终的数据文件已按分区生成；2) 使用`NautilusTrader`或类似工具加载数据，验证其格式合规、后复权价格计算完全正确、且加载性能达标；3) 通过数据库查询历史数据快照。

*   **故事 3.1: 本地数据存储**
    *   **作为** 一名数据工程师，
    *   **我想要** 最终的Gold层数据以本地数据库格式存储，
    *   **以便** 保障数据的一致性和可靠性，确保数据质量 (`system_design.md`)。
    *   **验收标准:**
        1.  数据写入是原子性的，不会出现部分写入的脏数据 (`TR-004`)。
        2.  可以查询历史数据，支持审计和回滚。
        3.  数据按`trade_date`和`symbol`进行分区，提升查询性能。

*   **故事 3.2: 严格的Schema变更控制**
    *   **作为** 一名量化分析师，
    *   **我想要** Gold层的数据Schema受到严格的版本控制，任何变更都必须通过团队的PR（Pull Request）评审，
    *   **以便** 保证Schema的稳定性和可预见性，防止因上游随意变更导致我的策略代码失效。
    *   **验收标准:**
        1.  Schema定义文件（如SQL DDL或配置）被纳入Git版本控制。
        2.  禁止直接在生产环境手动修改Schema。
        3.  优先采用向后兼容的变更（如添加列），破坏性变更需要充分评估和审批。

*   **故事 3.3: 策略回测就绪**
    *   **作为** 一名量化交易员，
    *   **我想要** 在每日市场收盘后60分钟内获得当日的、经过后复权的“黄金标准”Parquet数据，
    *   **以便** 我能立即进行策略回测和信号验证，快速迭代我的交易思想。
    *   **验收标准:**
        1.  端到端数据处理时间在95%的情况下小于60分钟 (`NFR-001`)。
        2.  加载单只股票全历史数据的耗时小于5秒 (`NFR-002`)。
        3.  所有OHLC价格均为后复权价，复权逻辑经过单元测试的严格验证 (`risk_register: DATA-03`)。

*   **故事 3.4: 实现精确的后复权价格计算**
    *   **作为** 一名数据工程师，
    *   **我想要** 实现一套精确、可验证的后复权价格计算逻辑，
    *   **以便** 消除所有公司行动（分红、送转股）对历史价格序列的影响，为量化回测提供数学上完全正确的价格数据。
    *   **验收标准:**
        1.  后复权因子(`adj_factor`)的计算逻辑被明确实现，并优先采用Tushare的数据 (`data_governance_and_dictionary.md`)。
        2.  所有历史的OHLC价格都基于`adj_factor`进行了调整。
        3.  存在专门的单元测试，覆盖了分红、送股、配股、拆股等多种场景。
        4.  选取至少5支股票，其计算出的后复权价格序列与权威金融终端（如Wind, Bloomberg）的复权数据进行抽样比对，误差在0.1%以内。

---

### Epic 4: 全链路数据质量保障与治理
**目标:** 建立一个主动、自动化、可度量的智能数据质量体系，将"质量内建"原则落到实处。
**可交付成果:** 一个集成了数据质量检查和监控系统的质量监控体系。团队可以演示：1) 监控看板上实时的多源一致性展示；2) 运行数据管道时，可以清晰地看到Bronze、Silver、Gold三道质量门禁被依次执行；3) 当注入不一致的数据时，系统如何自动告警并隔离数据；4) 每日生成的综合质量分。

*   **故事 4.1: 多源一致性实时告警与隔离**
    *   **作为** 一名数据质量分析师，
    *   **我想要** 当`miniQMT`与`Tushare`的收盘价差异持续超过0.5%时，系统能实时告警并自动隔离有问题的批次数据，
    *   **以便** 主动防止不一致的数据污染Gold层，保障核心数据的可信度 (`FR-008`, `NFR-005`)。
    *   **验收标准:**
        1.  一致性比率在监控看板上以热力图或时序图实时展示。
        2.  当比率持续低于99%时，触发P1级告警 (`CriticalMultiSourceConsistencyDrop`)。
        3.  被识别为不一致的数据批次会被移入一个隔离区，等待人工审核或自动修复，而不是直接进入Gold层。

*   **故事 4.2: 适应市场的动态质量阈值**
    *   **作为** 一名风控专员，
    *   **我想要** 在市场剧烈波动（如日均波幅 > 3%）时，系统能自动放宽一致性检查的容忍度（如从0.5%调整至0.75%），
    *   **以便** 提高告警的信噪比，避免在极端行情下被大量的“伪”告警淹没 (`quality_kpi.md`)。
    *   **验收标准:**
        1.  系统能计算市场波动率指标。
        2.  质量决策引擎在执行校验时，会从配置中心获取或动态计算出当前应使用的阈值。
        3.  阈值调整的逻辑和参数是可配置的。

*   **故事 4.3: 综合数据质量评分与报告**
    *   **作为** 一名项目经理，
    *   **我想要** 系统能为每日产出的数据计算一个综合质量分，并在简单Web界面上展示，
    *   **以便** 我能用一个顶层核心指标来衡量和报告整个数据管道的健康度和可信度，确保项目达成质量目标。
    *   **验收标准:**
        1.  质量分数的计算严格遵循`quality_kpi.md`中定义的权重模型。
        2.  该分数作为元数据字段`data_quality_score`存储在Gold层数据中。
        3.  月度平均质量分必须达到95分以上 (`NFR-004`)。

*   **故事 4.4: 建立并实施分层数据质量规则库**
    *   **作为** 一名数据质量分析师，
    *   **我想要** 建立一个包含至少120条规则的、以代码形式管理的数据质量规则库，并在数据管道中实施分层质量门禁，
    *   **以便** 将数据质量标准自动化、强制化，确保在数据生命周期的每个阶段都能主动发现和拦截问题。
    *   **验收标准:**
        1.  至少120条质量规则被定义为Python代码，并纳入Git版本控制 (`FR-007`)。
        2.  规则被组织为不同的检查套件，分别对应Bronze、Silver和Gold三层质量门禁。
        3.  任务调度器中集成了质量检查模块，在数据处理的相应步骤后执行这些质量门禁。
        4.  当关键规则在门禁中失败时，数据管道能按预设策略中断或发出告警。

---

### Epic 5: 系统韧性、安全与自动化运维
**目标:** 构建一个高可用、可自动恢复、安全可靠且易于管理的工业级系统。
**可交付成果:** 一个生产就绪的、具备高韧性的系统。团队可以演示：1) 通过Windows服务启动整个系统的所有组件；2) 通过修改配置文件，实时改变数据融合策略而无需重启服务；3) 运行故障模拟脚本，模拟`miniQMT`宕机，系统在2分钟内自动切换；4) 凭证存储在Windows凭据管理器中，代码库中无任何明文密钥。

*   **故事 5.1: 动态配置驱动的敏捷运维**
    *   **作为** 一名运维工程师，
    *   **我想要** 通过配置文件来动态管理数据源优先级、融合规则和质量阈值，
    *   **以便** 在不重新部署代码的情况下，就能实时调整系统的核心行为，实现敏捷响应 (`system_design.md`)。
    *   **验收标准:**
        1.  系统在启动或运行时会从配置文件加载配置。
        2.  修改配置文件内的规则（如将Tushare优先级调高）后，数据处理逻辑会立即生效。
        3.  代码中没有硬编码的业务规则或阈值。

*   **故事 5.2: 通过混沌工程验证系统韧性**
    *   **作为** 一名DevOps工程师，
    *   **我想要** 每月定期执行混沌工程实验，如通过工具主动注入API故障或网络延迟，
    *   **以便** 科学地、主动地验证系统的自动故障转移机制是否能在2分钟内按预期工作，增强我们对系统韧性的信心 (`risk_register: OPS-01`)。
    *   **验收标准:**
        1.  混沌工程实验被定义为可重复执行的脚本或Windows任务。
        2.  在模拟主数据源`miniQMT`故障后，系统能在2分钟内自动切换到`Tushare` (`BR-004`)。
        3.  实验结果（成功、失败、耗时）被记录下来，用于持续改进。

*   **故事 5.3: 安全的运行时凭证管理**
    *   **作为** 一名安全官，
    *   **我想要** 所有的API Token和数据库密码都通过Windows凭据管理器进行管理，并动态注入到应用进程中，
    *   **以便** 杜绝任何形式的凭证硬编码，实现凭证的集中、安全管理和轻松轮换 (`risk_register: SEC-01`, `NFR-006`)。
    *   **验收标准:**
        1.  应用进程通过环境变量或Windows凭据管理器获取凭证，而不是从配置文件中读取。
        2.  CI/CD流程中的安全扫描（如`git-secrets`）确保没有任何凭证被提交到代码库。
        3.  对凭证的访问有严格的审计日志。

*   **故事 5.4: 可视化的成本与配额监控**
    *   **作为** 一名项目经理，
    *   **我想要** 在监控仪表盘上有一个专门的面板来可视化Tushare积分的消耗趋势和本地存储的使用情况，
    *   **以便** 我能主动进行成本管理和预算控制，避免资源超支 (`risk_register: RSK-02`)。
    *   **验收标准:**
        1.  监控仪表盘能展示Tushare配额的每日/每周消耗量和剩余量。
        2.  能展示本地数据存储的总大小和增长趋势。
        3.  当成本或配额消耗超过预算的90%时，系统能自动发送告警。

*   **故事 5.5: 实现Windows服务部署**
    *   **作为** 一名DevOps工程师，
    *   **我想要** 将系统的所有组件（采集器、处理器、API服务等）部署为Windows服务，并提供自动化部署脚本，
    *   **以便** 实现环境一致性、进程隔离和自动化部署，极大简化开发、测试和运维流程。
    *   **验收标准:**
        1.  系统的每个独立组件都可以作为Windows服务运行。
        2.  提供PowerShell部署脚本，能够通过一键命令成功启动所有服务 (`TR-001`)。
        3.  服务间的依赖关系在部署脚本中正确定义。
        4.  CI/CD流水线被配置为在代码合并后自动构建和部署Windows服务包。

---

### Epic 6: (未来规划) AI集成与智能化扩展
**目标:** 探索并利用`xtquantai`的MCP特性，实现与AI工具的集成，提升数据分析与操作的智能化水平。

*   **故事 6.1: 通过AI助手查询QMT数据**
    *   **作为** 一名高级量化分析师，
    *   **我想要** 通过AI助手（如Cursor或自定义AI应用）使用自然语言或特定指令，直接查询`Windows QMT Data Agent`（运行在MCP模式下）获取miniQMT中的数据，
    *   **以便** 更快速、更便捷地进行探索性数据分析和策略思路验证，而无需编写复杂的查询脚本。
    *   **验收标准:**
        1.  `Windows QMT Data Agent`能够以MCP服务器模式成功启动并运行。
        2.  AI助手能够通过MCP协议连接到该Agent。
        3.  可以通过AI助手成功执行至少三种不同类型的QMT数据查询（例如：获取某股票的最新行情、查询某日期区间的历史K线、获取某板块的成分股）。
        4.  查询结果在AI助手中正确展示。
        5.  相关操作和交互过程有清晰的文档记录。

*   **故事 6.2: AI辅助的图表生成**
    *   **作为** 一名策略研究员，
    *   **我想要** AI助手能够调用`Windows QMT Data Agent`（MCP模式）的图表生成功能，
    *   **以便** 快速可视化特定股票的技术指标（如MA, MACD），辅助我进行技术分析。
    *   **验收标准:**
        1.  AI助手可以成功调用Agent的`create_chart_panel`或类似功能。
        2.  QMT客户端能够根据指令正确显示生成的图表。
        3.  支持至少两种常用技术指标的图表生成。